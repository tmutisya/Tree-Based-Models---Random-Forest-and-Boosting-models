# Tree-Based-Models---Bagging-and-Boosting-models
Tree-based models use hierarchical decision rules to capture complex, non-linear relationships and interactions among variables without requiring strict assumptions about the data distribution. They often achieve better results than linear models because they automatically handle feature interactions and nonlinearity, leading to higher predictive accuracy and robustness in real-world, complex datasets. 
The tree-based modeling approach begins by recursively splitting the dataset into subsets based on feature values that best reduce prediction error or impurity. 
Each split creates decision rules that capture non-linear relationships and interactions among predictors. 
Ensemble methods such as random forests and gradient boosting improve this approach by combining many trees to reduce variance and bias. 
As a result, tree-based models achieve robust, high-performing predictions while requiring minimal data preprocessing. 
